{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%writefile requirments.txt\n",
        "datasets\n",
        "trl\n",
        "peft"
      ],
      "metadata": {
        "id": "mrRDm2-beqgT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirments.txt"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Des51tQjfuzO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "from transformers import AutoTokenizer\n",
        "from peft import LoraConfig\n",
        "from transformers import AutoModelForCausalLM\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from trl import SFTTrainer\n",
        "from transformers import TrainingArguments\n",
        "from peft import PeftModel\n",
        "from transformers import AutoModelForCausalLM"
      ],
      "metadata": {
        "id": "ymrTG9fOokXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = load_dataset(\"FinGPT/fingpt-sentiment-train\", split=\"train\")\n",
        "print(ds[0])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "YMYSl_7SpAj7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample_text(example):\n",
        "    text = (\n",
        "        f\"{example['instruction']}\\n\"\n",
        "        f\"Content: {example['input']}\\n\"\n",
        "        f\"Sentiment: {example['output']}\"\n",
        "    )\n",
        "    return {\"text\": text}\n"
      ],
      "metadata": {
        "id": "sn3M99NLq2sU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.map(sample_text, remove_columns=[\"instruction\", \"input\", \"output\"])\n",
        "print(next(iter(ds[\"text\"])))"
      ],
      "metadata": {
        "collapsed": true,
        "id": "cdHiyhqW9qCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = ds.train_test_split(test_size=0.2, seed=42)\n",
        "ds_train = ds[\"train\"]\n",
        "ds_eval = ds[\"test\"]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nBC-p-_JFfmx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-1.3b\")"
      ],
      "metadata": {
        "collapsed": true,
        "id": "39GsYVyku5y6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lora_config = LoraConfig(\n",
        "    r = 16,\n",
        "    lora_alpha = 32,\n",
        "    lora_dropout = 0.05,\n",
        "    bias = \"none\",\n",
        "    task_type = \"CAUSAL_LM\",\n",
        ")"
      ],
      "metadata": {
        "id": "7ZWk6ookGg-b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\"facebook/opt-1.3b\", torch_dtype = torch.float16, device_map=\"auto\")"
      ],
      "metadata": {
        "id": "K4HoNBgnKSXI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.parameters():\n",
        "  param.requires_grad = False\n",
        "  if param.ndim == 1:\n",
        "    param.data = param.data.to(torch.float16)\n",
        "\n",
        "model.gradient_checkpointing_enable\n",
        "model.enable_input_require_grads\n",
        "\n",
        "class OutputToFloat(nn.Sequential):\n",
        "  def forward(self, x):\n",
        "    return super().forward(x).to(torch.float16)\n",
        "\n",
        "model.lm_head = OutputToFloat(model.lm_head)"
      ],
      "metadata": {
        "id": "0Jf6BTv9LckO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./OPT-fine_tuned-FinGPT-CPU\",\n",
        "    dataloader_drop_last=True,\n",
        "    max_steps = 10,\n",
        "    save_strategy=\"steps\",\n",
        "    num_train_epochs=10,\n",
        "    logging_steps=5,\n",
        "    per_device_train_batch_size=12,\n",
        "    per_device_eval_batch_size=12,\n",
        "    learning_rate=1e-4,\n",
        "    lr_scheduler_type=\"cosine\",\n",
        "    warmup_steps=100,\n",
        "    gradient_accumulation_steps=1,\n",
        "    gradient_checkpointing=False,\n",
        "    fp16=False,\n",
        "    bf16=True,\n",
        "    weight_decay=0.05,\n",
        "    ddp_find_unused_parameters=False,\n",
        "    run_name=\"OPT-fine_tuned-FinGPT-CPU\",\n",
        "    report_to=\"wandb\",\n",
        ")"
      ],
      "metadata": {
        "id": "lvyFk-IVUJ8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = SFTTrainer(\n",
        "    model = model,\n",
        "    args = training_args,\n",
        "    train_dataset = ds_train,\n",
        "    eval_dataset = ds_eval,\n",
        "    peft_config = lora_config,\n",
        ")\n",
        "\n",
        "print(\"Training...\")\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "zMHGVmRzN4Rg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "  \"facebook/opt-1.3b\", return_dict=True, torch_dtype=torch.bfloat16\n",
        ")"
      ],
      "metadata": {
        "id": "GzCXS1QZaa4c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = PeftModel.from_pretrained(model, \"./OPT-fine_tuned-FinGPT-CPU/checkpoint-10/\")\n",
        "model.eval()\n",
        "model = model.merge_and_unload()\n",
        "model.save_pretrained(\"./OPT-fine_tuned-FinGPT-CPU/merged\")"
      ],
      "metadata": {
        "id": "tpcUSfhtbRod"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}